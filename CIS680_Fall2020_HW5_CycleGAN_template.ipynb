{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIS680_Fall2020_HW5_CycleGAN_template.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4v6rxBKYp7Z"
      },
      "source": [
        "# Download the dataset and supporting codes and pre-trained models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIMdTpeGg-Vw"
      },
      "source": [
        "https://drive.google.com/file/d/1D3m6I2S8xIvdOHBkvwSSFof5OTJZCDSt/view?usp=drivesdk\n",
        "\n",
        "https://drive.google.com/file/d/1CDRMyBA3Hk_gmbk1xkAm7aRHXBOQQigu/view?usp=drivesdk\n",
        "\n",
        "https://drive.google.com/file/d/1so6AQ0_Pg255COjAzEOOVPlDzTJFVQro/view?usp=drivesdk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CQQXc9JUUYU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63143e31-5653-4e7c-faca-0fd7968fd08b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CW3wE6aNYekA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9443adb3-25fc-4442-939a-0d4b1f0444ba"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from googleapiclient.discovery import build\n",
        "drive_service = build('drive', 'v3')\n",
        "import io\n",
        "import os\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "def download_file(fn, file_id):\n",
        "    request = drive_service.files().get_media(fileId=file_id)\n",
        "    downloaded = io.BytesIO()\n",
        "    downloader = MediaIoBaseDownload(downloaded, request)\n",
        "    done = False\n",
        "    while done is False:\n",
        "        # _ is a placeholder for a progress object that we ignore.\n",
        "        # (Our file is small, so we skip reporting progress.)\n",
        "        _, done = downloader.next_chunk()\n",
        "    downloaded.seek(0)\n",
        "    folder = fn.split('/')\n",
        "    if len(folder) > 1:\n",
        "        os.makedirs(folder[0], exist_ok=True)\n",
        "    with open(fn, 'wb') as f:\n",
        "        f.write(downloaded.read())\n",
        "id_to_fn = {\n",
        "# '1D3rH-gSxIECZnoyc5k77PEucKBVzoiBc': 'edges2shoes.zip',\n",
        "'1D3m6I2S8xIvdOHBkvwSSFof5OTJZCDSt': 'edges2shoes.zip',\n",
        "'1CDRMyBA3Hk_gmbk1xkAm7aRHXBOQQigu': 'CycleGAN_support.zip',\n",
        "# '1so6AQ0_Pg255COjAzEOOVPlDzTJFVQro': 'test_case.zip',\n",
        "'1l7gHikhCz64hYHL4n_Ps7nufQcddcRyR': 'test_case.zip'\n",
        "\n",
        "}\n",
        "# download all files into the vm\n",
        "for fid, fn in id_to_fn.items():\n",
        "    print(\"Downloading %s from %s\" % (fn, fid))\n",
        "    download_file(fn, fid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading edges2shoes.zip from 1D3m6I2S8xIvdOHBkvwSSFof5OTJZCDSt\n",
            "Downloading CycleGAN_support.zip from 1CDRMyBA3Hk_gmbk1xkAm7aRHXBOQQigu\n",
            "Downloading test_case.zip from 1l7gHikhCz64hYHL4n_Ps7nufQcddcRyR\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIZPNwOJZUB7"
      },
      "source": [
        "! unzip -q edges2shoes.zip\n",
        "! unzip -q CycleGAN_support.zip\n",
        "! unzip -q test_case.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rT6-1Ax8YyQr"
      },
      "source": [
        "# CycleGAN training (TODO)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zQDWN_lMWJI"
      },
      "source": [
        "import torch\n",
        "import pdb\n",
        "\n",
        "D_A = torch.load('test_case/D_A.pt')\n",
        "D_B = torch.load('test_case/D_B.pt')\n",
        "G_BA = torch.load('test_case/G_BA.pt')\n",
        "G_AB = torch.load('test_case/G_AB.pt')\n",
        "valid = torch.load('test_case/valid.pt')\n",
        "fake = torch.load('test_case/fake.pt')\n",
        "fake_A = torch.load('test_case/fake_A.pt')\n",
        "fake_B = torch.load('test_case/fake_B.pt')\n",
        "real_A = torch.load('test_case/real_A.pt')\n",
        "real_B = torch.load('test_case/real_B.pt')\n",
        "criterion_GAN = torch.load('test_case/criterion_GAN.pt')\n",
        "criterion_cycle = torch.load('test_case/criterion_cycle.pt')\n",
        "\n",
        "\n",
        "\n",
        "def loss_discriminator(fakefG, D, real2D, valid, fake, criterion_GAN):\n",
        "    '''\n",
        "    loss_discriminator function is applied to compute loss for discriminator D_A and D_B,\n",
        "    For example, we want to compute loss for D_A. The loss is consisted of two parts: \n",
        "    D(real_A) and D(G(real_B)). We want to penalize the distance between D(real_A) part and 1 and \n",
        "    distance between D(G(real_B)) part and 0. \n",
        "    We will want to first compute discriminator loss given real_A and valid, which is all 1.\n",
        "    Then we want to forward real_A through G_AB network to get fake image batch \n",
        "    and compute discriminator loss given fake batch and fake, which is all 0.\n",
        "    Finall, add up these two loss as the total discriminator loss.\n",
        "    '''\n",
        "    \n",
        "\n",
        "    return loss_D\n",
        "\n",
        "\n",
        "\n",
        "def loss_generator(G, real2G, D, valid, criterion_GAN):\n",
        "    '''\n",
        "    loss_generator function is applied to compute loss for both generator G_AB and G_BA:\n",
        "    For example, we want to compute the loss for G_AB.\n",
        "    real2G will be the real image in domain A, then we map real2G into domain B to get fake B,\n",
        "    then we compute the loss between D_B(fake_B) and valid, which is all 1.\n",
        "    The fake_B image will also be one of the outputs, since we want to use it in the loss_cycle_consis.\n",
        "    '''\n",
        "    \n",
        "    return loss_G, fake_o_G\n",
        "\n",
        "\n",
        "\n",
        "def loss_cycle_consis(G, fakefG, real, criterion_cycle):\n",
        "    '''\n",
        "    loss_cycle_consis function is applied to both cycle consistency loss:\n",
        "    between recovered A and original A,\n",
        "    between recovered B and original B.\n",
        "    For example, we want to compute the cycle consistency loss between recovered A and original A.\n",
        "    fake2G will be the generated image in domain B, then we map fake2G back into domain A to get recovered A,\n",
        "    then we compute the loss between recovered A and original A\n",
        "    '''\n",
        "    \n",
        "    return loss_cycle\n",
        "\n",
        "\n",
        "# test case\n",
        "\n",
        "test_loss_GAN_AB = torch.load('test_case/loss_GAN_AB.pt')\n",
        "test_loss_cycle_A = torch.load('test_case/loss_cycle_A.pt')\n",
        "test_loss_D_A = torch.load('test_case/loss_D_A.pt')\n",
        "loss_GAN_AB, fake_B = loss_generator(G_AB, real_A, D_B, valid, criterion_GAN)\n",
        "loss_cycle_A = loss_cycle_consis(G_BA, fake_B, real_A, criterion_cycle)\n",
        "loss_D_A = loss_discriminator(fake_A, D_A, real_A, valid, fake, criterion_GAN)\n",
        "\n",
        "\n",
        "print('test case loss_D_A:', test_loss_D_A.item())\n",
        "print('computed loss_D_A:', loss_D_A.item())\n",
        "\n",
        "print('test case test_loss_GAN_AB:', test_loss_GAN_AB.item())\n",
        "print('computed test_loss_GAN_AB:', loss_GAN_AB.item())\n",
        "\n",
        "print('test case loss_cycle_A:', test_loss_cycle_A.item())\n",
        "print('computed loss_cycle_A:', loss_cycle_A.item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sM1-EnX11hXX"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from torch.autograd import Variable\n",
        "from torch.utils import data\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch import nn, optim\n",
        "from datasets import *\n",
        "from models import *\n",
        "import argparse, os\n",
        "import itertools\n",
        "import torch\n",
        "import time\n",
        "import pdb\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Training Configurations\n",
        "# (You may put your needed configuration here. Please feel free to add more or use argparse. )\n",
        "train_img_dir = './edges2shoes/train/'\n",
        "img_shape = (3, 128, 128)\n",
        "n_residual_blocks = 6\n",
        "num_epochs = 2\n",
        "batch_size = 1\n",
        "lr_rate = 0.0002      # Adam optimizer learning rate\n",
        "betas = (0.5, 0.999)  # Adam optimizer beta 1, beta 2\n",
        "lambda_cyc = 10.0 \t  # cycle loss weight\n",
        "latent_dim = 8        # latent dimension for the encoded images from domain B\n",
        "report_feq = 10        # Visualize image every 'report_feq' iters\n",
        "visual_feq = 1000\n",
        "save_feq = 1000      # Save models every 'save_feq' iters\n",
        "\n",
        "# Random seeds (optional)\n",
        "torch.manual_seed(1); np.random.seed(1)\n",
        "\n",
        "# set device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Normalize image tensor\n",
        "def norm(image):\n",
        "    return (image/255.0-0.5)*2.0\n",
        "\n",
        "# Denormalize image tensor\n",
        "def denorm(tensor):\n",
        "    return ((tensor+1.0)/2.0)*255.0\n",
        "\n",
        "train_dataset = Edge2Shoe(train_img_dir)\n",
        "train_loader = data.DataLoader(train_dataset, batch_size=batch_size)\n",
        "print('the length of training data:', len(train_dataset))\n",
        "# Losses\n",
        "criterion_GAN = torch.nn.MSELoss()\n",
        "criterion_cycle = torch.nn.L1Loss()\n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "\n",
        "input_shape = img_shape\n",
        "\n",
        "# Initialize generator and discriminator\n",
        "G_AB = GeneratorResNet(input_shape, n_residual_blocks)\n",
        "G_BA = GeneratorResNet(input_shape, n_residual_blocks)\n",
        "D_A = Discriminator(input_shape)\n",
        "D_B = Discriminator(input_shape)\n",
        "\n",
        "\n",
        "if cuda:\n",
        "    G_AB = G_AB.to(device)\n",
        "    G_BA = G_BA.to(device)\n",
        "    D_A = D_A.to(device)\n",
        "    D_B = D_B.to(device)\n",
        "    criterion_GAN.to(device)\n",
        "    criterion_cycle.to(device)\n",
        "\n",
        "# Initialize weights\n",
        "G_AB.apply(weights_init_normal)\n",
        "G_BA.apply(weights_init_normal)\n",
        "D_A.apply(weights_init_normal)\n",
        "D_B.apply(weights_init_normal)\n",
        "\n",
        "\n",
        "\n",
        "# Define optimizer\n",
        "optimizer_G = torch.optim.Adam(itertools.chain(G_AB.parameters(), G_BA.parameters()), lr=lr_rate, betas=betas)\n",
        "optimizer_D_A = torch.optim.Adam(D_A.parameters(), lr=lr_rate, betas=betas)\n",
        "optimizer_D_B = torch.optim.Adam(D_B.parameters(), lr=lr_rate, betas=betas)\n",
        "\n",
        "# For adversarial loss\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor\n",
        "\n",
        "# loss recorder\n",
        "running_loss_D_A = 0\n",
        "running_loss_D_B = 0\n",
        "running_loss_GAN_AB = 0\n",
        "running_loss_GAN_BA = 0\n",
        "running_loss_cycle = 0\n",
        "running_total_loss = 0\n",
        "\n",
        "loss_D_A = []\n",
        "loss_D_B = []\n",
        "loss_GAN_AB = []\n",
        "loss_GAN_BA = []\n",
        "loss_cycle = []\n",
        "total_loss = []\n",
        "# Training\n",
        "total_steps = len(train_loader)*num_epochs; step = 0\n",
        "for e in range(num_epochs):\n",
        "    start = time.time()\n",
        "    for idx, data in enumerate(train_loader):\n",
        "        ########## Process Inputs ##########\n",
        "        edge_tensor, rgb_tensor = data\n",
        "        edge_tensor, rgb_tensor = norm(edge_tensor).to(device), norm(rgb_tensor).to(device)\n",
        "        real_A = edge_tensor; real_B = rgb_tensor;\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        valid = Variable(Tensor(np.ones((real_A.size(0), *D_A.output_shape))), requires_grad=False)\n",
        "        fake = Variable(Tensor(np.zeros((real_A.size(0), *D_A.output_shape))), requires_grad=False)\n",
        "\n",
        "        # ------------------\n",
        "        #  Train Generators\n",
        "        # ------------------\n",
        "        G_AB.train(); G_BA.train()\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # Generator loss\n",
        "        loss_GAN_AB, fake_B = loss_generator(G_AB, real_A, D_B, valid, criterion_GAN)\n",
        "        loss_GAN_BA, fake_A = loss_generator(G_BA, real_B, D_A, valid, criterion_GAN)\n",
        "        loss_GAN = (loss_GAN_AB + loss_GAN_BA) / 2\n",
        "\n",
        "        # Cycle loss\n",
        "        loss_cycle_A = loss_cycle_consis(G_BA, fake_B, real_A, criterion_cycle)\n",
        "        loss_cycle_B = loss_cycle_consis(G_AB, fake_A, real_B, criterion_cycle)\n",
        "        loss_cycle = (loss_cycle_A + loss_cycle_B) / 2\n",
        "\n",
        "        # Total loss\n",
        "        loss_G = loss_GAN + lambda_cyc * loss_cycle\n",
        "\n",
        "        loss_G.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "\n",
        "        # -----------------------\n",
        "        #  Train Discriminator A\n",
        "        # -----------------------\n",
        "\n",
        "        optimizer_D_A.zero_grad()\n",
        "\n",
        "        # function to compute loss_D_A\n",
        "        loss_D_A = loss_discriminator(fake_A, D_A, real_A, valid, fake, criterion_GAN)\n",
        "        loss_D_A = loss_D_A / 2\n",
        "        # update the D_A network\n",
        "        loss_D_A.backward()\n",
        "        optimizer_D_A.step()\n",
        "\n",
        "\n",
        "        # -----------------------\n",
        "        #  Train Discriminator B\n",
        "        # -----------------------\n",
        "        optimizer_D_B.zero_grad()\n",
        "\n",
        "        # function to compute loss_D_A\n",
        "        loss_D_B = loss_discriminator(fake_B, D_B, real_B, valid, fake, criterion_GAN)\n",
        "        loss_D_B = loss_D_B / 2\n",
        "        # update the D_B network\n",
        "        loss_D_B.backward()\n",
        "        optimizer_D_B.step()\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "        running_total_loss += (loss_GAN + lambda_cyc * loss_cycle + loss_D_A + loss_D_B).item()\n",
        "\n",
        "        running_loss_GAN_AB += loss_GAN_AB.item()\n",
        "        running_loss_GAN_BA += loss_GAN_BA.item()\n",
        "        running_loss_D_A += loss_D_A.item()\n",
        "        running_loss_D_B += loss_D_B.item()\n",
        "        running_loss_cycle += lambda_cyc * loss_cycle.item()\n",
        "        ########## Visualization ##########\n",
        "        if step % report_feq == report_feq-1:\n",
        "            print('Train Epoch: {} {:.0f}% \\tTotal Loss: {:.6f} \\tLoss_G_AB: {:.6f}\\tLoss_G_BA: {:.6f}\\tLoss_cycle: {:.6f}\\tLoss_D_A: {:.6f}\\tLoss_D_B: {:.6f}'.format\n",
        "                    (e+1, 100. * idx / len(train_loader), running_total_loss / report_feq, \n",
        "                    running_loss_GAN_AB/report_feq, running_loss_GAN_BA/report_feq, \n",
        "                    running_loss_cycle/report_feq, running_loss_D_A/report_feq, \n",
        "                    running_loss_D_B/report_feq))\n",
        "            running_loss_D_A = 0\n",
        "            running_loss_D_B = 0\n",
        "            running_loss_GAN_AB = 0\n",
        "            running_loss_GAN_BA = 0\n",
        "            running_loss_cycle = 0\n",
        "            running_total_loss = 0\n",
        "            end = time.time()\n",
        "            print(e, step, 'T: ', end-start)\n",
        "            start = end\n",
        "        ########## Visualize Generated images ##########\n",
        "        if step % visual_feq == 0:\n",
        "            vis_fake_A = denorm(fake_A[0].detach()).cpu().data.numpy().astype(np.uint8)\n",
        "            vis_fake_B = denorm(fake_B[0].detach()).cpu().data.numpy().astype(np.uint8)\n",
        "            vis_real_B = denorm(real_B[0].detach()).cpu().data.numpy().astype(np.uint8)\n",
        "            vis_real_A = denorm(real_A[0].detach()).cpu().data.numpy().astype(np.uint8)\n",
        "            fig, axs = plt.subplots(2,2, figsize = (5,5))\t\n",
        "            \n",
        "            axs[0,0].imshow(vis_real_A.transpose(1,2,0))\n",
        "            axs[0,0].set_title('real images')\n",
        "            axs[0,1].imshow(vis_fake_B.transpose(1,2,0))\n",
        "            axs[0,1].set_title('generated images')\n",
        "            axs[1,0].imshow(vis_real_B.transpose(1,2,0))\n",
        "            axs[1,1].imshow(vis_fake_A.transpose(1,2,0))\n",
        "            plt.show()\n",
        "        ########## Save Generators ##########\n",
        "        if step % save_feq == save_feq-1:\n",
        "            if not os.path.exists('models'): os.mkdir('models')\n",
        "            torch.save(G_AB, '/content/models/G_AB.pt')\n",
        "            torch.save(G_BA, '/content/models/G_BA.pt')\n",
        "            # feel free to save checkpoint if you need retrain the model...\n",
        "\n",
        "        step += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yx1sPwiu_04L"
      },
      "source": [
        "# CycleGAN testing (TODO)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_5OoGMfKFuU"
      },
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "test_batch_size = 1\n",
        "test_img_dir = './edges2shoes/val/'\n",
        "test_dataset = Edge2Shoe(test_img_dir)\n",
        "test_loader = DataLoader(test_dataset, batch_size=test_batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naYmwWpq9Eg_"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "G_AB = torch.load('/content/models/G_AB.pt')\n",
        "G_BA = torch.load('/content/models/G_BA.pt')\n",
        "if cuda:\n",
        "    G_AB = G_AB.to(device)\n",
        "    G_BA = G_BA.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7m1b2H0pLOfu"
      },
      "source": [
        "G_AB.eval()\n",
        "G_BA.eval()\n",
        "\n",
        "################################\n",
        "# Please visualize real_edge, fake_shoe, real_shoe, fake_edge in 2-by-2 grids:\n",
        "\n",
        "################################        \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnLrUjjVfxA-"
      },
      "source": [
        "# Quantitative Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-T0HP1fBO1j"
      },
      "source": [
        "## FID Score computation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wgxl2Y9gsJ8_"
      },
      "source": [
        "First, we have to create 6 datasets:\n",
        "- Domain A real set 1\n",
        "- Domain A real set 2\n",
        "- Domain A generate set\n",
        "\n",
        "- Domain B real set 1\n",
        "- Domain B real set 2\n",
        "- Domain B generate set\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBkdwX3sf2qb"
      },
      "source": [
        "Create folder to save images and create dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKIC1KfjvUsH"
      },
      "source": [
        "! mkdir real_A_1 real_A_2 gen_A\n",
        "! mkdir real_B_1 real_B_2 gen_B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYMyd8CuBPJz"
      },
      "source": [
        "# First create test data loader\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision.utils import save_image\n",
        "test_batch_size = 1\n",
        "test_img_dir = './edges2shoes/val/'\n",
        "test_dataset = Edge2Shoe(test_img_dir)\n",
        "test_loader = DataLoader(test_dataset, batch_size=test_batch_size)\n",
        "\n",
        "# indicate the device we will use\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load learnt Generator G_AB and G_BA\n",
        "G_AB = torch.load('/content/models/G_AB.pt').to(device)\n",
        "G_BA = torch.load('/content/models/G_BA.pt').to(device)\n",
        "\n",
        "# the size of dataset, we want to evaluate on\n",
        "evaluate_num = 100\n",
        "\n",
        "# make the gen data set and folder\n",
        "real_A_set_1 = []\n",
        "real_A_set_2 = []\n",
        "real_B_set_1 = []\n",
        "real_B_set_2 = []\n",
        "\n",
        "gen_set_A = []\n",
        "gen_set_B = []\n",
        "\n",
        "for idx, data in enumerate(test_loader, 0):\n",
        "    real_A, real_B = data\n",
        "    # plt.imshow(real_A.type(torch.uint8).squeeze(0).cpu().permute(1,2,0))\n",
        "    # plt.show()\n",
        "    real_A, real_B = norm(real_A).to(device), norm(real_B).to(device)\n",
        "    # plt.imshow(denorm(real_A).type(torch.uint8).squeeze(0).cpu().permute(1,2,0))\n",
        "    # plt.imshow(denorm(real_A).squeeze(0).cpu().permute(1,2,0))\n",
        "    # plt.show()\n",
        "    # print(real_A.shape)\n",
        "    \n",
        "    if idx < evaluate_num:\n",
        "        fake_A = G_BA(real_B)\n",
        "        fake_B = G_AB(real_A)\n",
        "        real_A_set_1.append(denorm(real_A.detach()))\n",
        "        real_B_set_1.append(denorm(real_B.detach()))\n",
        "        gen_set_A.append(denorm(fake_A.detach()))\n",
        "        gen_set_B.append(denorm(fake_B.detach()))\n",
        "        \n",
        "        # plt.imshow(data[0].type(torch.uint8).squeeze(0).permute(1,2,0))\n",
        "        # plt.imshow(denorm(real_A).squeeze(0).cpu().permute(1,2,0))\n",
        "        # plt.imshow(denorm(real_A).type(torch.uint8).squeeze(0).cpu().permute(1,2,0))\n",
        "        # plt.show()\n",
        "        plt.imsave('./real_A_1/real_A' + str(idx) + '.png', denorm(real_A).type(torch.uint8).cpu().squeeze().permute(1,2,0).numpy())\n",
        "        plt.imsave('./real_B_1/real_B' + str(idx) + '.png', denorm(real_B).type(torch.uint8).cpu().squeeze().permute(1,2,0).numpy())\n",
        "        plt.imsave('./gen_A/gen_A' + str(idx) + '.png', denorm(fake_A).type(torch.uint8).cpu().squeeze().permute(1,2,0).numpy())\n",
        "        plt.imsave('./gen_B/gen_B' + str(idx) + '.png', denorm(fake_B).type(torch.uint8).cpu().squeeze().permute(1,2,0).numpy())\n",
        "        # save_image(denorm(real_A).type(torch.uint8).squeeze(), './real_A_1/real_A' + str(idx) + '.png', normalize=False)\n",
        "\n",
        "        # save_image(denorm(real_B).detach().squeeze(), './real_B_1/real_B' + str(idx) + '.png', normalize=False)\n",
        "        # save_image(denorm(fake_A).detach().squeeze(), './gen_A/gen_A' + str(idx) + '.png', normalize=False)\n",
        "        # save_image(denorm(fake_B).detach().squeeze(), './gen_B/gen_B' + str(idx) + '.png', normalize=False)\n",
        "        # del real_A; del real_B; del fake_A; del fake_B\n",
        "\n",
        "    elif evaluate_num <= idx < 2*evaluate_num:\n",
        "        real_A_set_2.append(real_A.detach())\n",
        "        real_B_set_2.append(real_B.detach())\n",
        "        plt.imsave('./real_A_2/real_A' + str(idx) + '.png', denorm(real_A).type(torch.uint8).cpu().squeeze().permute(1,2,0).numpy())\n",
        "        plt.imsave('./real_B_2/real_B' + str(idx) + '.png', denorm(real_B).type(torch.uint8).cpu().squeeze().permute(1,2,0).numpy())\n",
        "        # save_image(denorm(real_A).detach().squeeze(), './real_A_2/real_A' + str(idx) + '.png', normalize=False)\n",
        "        # save_image(denorm(real_B).detach().squeeze(), './real_B_2/real_B' + str(idx) + '.png', normalize=False)\n",
        "    \n",
        "    if idx == 2*evaluate_num-1:\n",
        "        break\n",
        "# make 6 pytorch dataset\n",
        "real_A_dataset_1 = TensorDataset(torch.cat(real_A_set_1))\n",
        "real_A_dataset_2 = TensorDataset(torch.cat(real_A_set_2))\n",
        "real_B_dataset_1 = TensorDataset(torch.cat(real_B_set_1))\n",
        "real_B_dataset_2 = TensorDataset(torch.cat(real_B_set_2))\n",
        "gen_dataset_A = TensorDataset(torch.cat(gen_set_A))\n",
        "gen_dataset_B = TensorDataset(torch.cat(gen_set_B))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVQjy_tuGPdm"
      },
      "source": [
        "## Compute FID score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hJpNaRcGOQl"
      },
      "source": [
        "! pip install pytorch-fid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2q_mIuDK8wP"
      },
      "source": [
        "print('computing FID score between real_edge_1 and real_edge_2')\n",
        "! python -m pytorch_fid '/content/real_A_1' '/content/real_A_2' --gpu 0\n",
        "\n",
        "print('computing FID score between real_edge_1 and gen_edge')\n",
        "! python -m pytorch_fid '/content/real_A_1' '/content/gen_A' --gpu 0\n",
        "\n",
        "print('computing FID score between real_shoe_1 and real_shoe_2')\n",
        "! python -m pytorch_fid '/content/real_B_1' '/content/real_B_2' --gpu 0\n",
        "\n",
        "print('computing FID score between real_shoe_1 and gen_shoe')\n",
        "! python -m pytorch_fid '/content/real_B_1' '/content/gen_B' --gpu 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNG7AkY_Gt61"
      },
      "source": [
        "## Compute IS score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qC7FTAYHFGV2"
      },
      "source": [
        "from inception_score import inception_score\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print('IS score for real_edge_1 data set:')\n",
        "print(inception_score(real_A_dataset_1, cuda=True, batch_size=64, resize=True, splits=1))\n",
        "print('IS score for gen_edge data set:')\n",
        "print(inception_score(gen_dataset_A, cuda=True, batch_size=64, resize=True, splits=1))\n",
        "\n",
        "\n",
        "print('IS score for real_shoe_1:')\n",
        "print(inception_score(real_B_dataset_1, cuda=True, batch_size=64, resize=True, splits=1))\n",
        "print('IS score for gen_shoe data set:')\n",
        "print(inception_score(gen_dataset_B, cuda=True, batch_size=64, resize=True, splits=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJcwTlhcDvmE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}